# -*- coding: utf-8 -*-
"""NER - Fuzzy Logic Matching

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mylrrnsvc-rgSYTcl0d_cx5rVQ0vujOj
"""

!pip install --upgrade gspread

!pip install fuzzywuzzy

!pip install python-Levenshtein

from google.colab import auth
auth.authenticate_user()

import gspread
from google.auth import default
creds, _ = default()
import pandas as pd
from fuzzywuzzy import fuzz
from fuzzywuzzy import process
import spacy

!python -m spacy download en_core_web_lg

gc = gspread.authorize(creds)

ss = gc.open_by_key('1P49aXnglaf_4EcJbszUdavnOJSzv6RR1lWrRfjedKcE')

wsTable = ss.worksheet("Table")
# get_all_values gives a list of rows.
rows = wsTable.get_all_values()

# Convert to a DataFrame and render.
dfTable = pd.DataFrame.from_records(rows[1:],columns=rows[0])
print(dfTable)

wsTestTable = ss.worksheet("TestTable")
# get_all_values gives a list of rows.
rowsT = wsTestTable.get_all_values()

# Convert to a DataFrame and render.
dfTestTable = pd.DataFrame.from_records(rowsT[1:],columns=rowsT[0])
print(dfTestTable)

nlp = spacy.load("en_core_web_lg")

def clean_text(text):
    doc = nlp(text)
    cleaned_tokens = [token.text for token in doc if not token.is_stop and token.is_alpha]
    return " ".join(cleaned_tokens)

def remove_geographical_locations(text):
    doc = nlp(text)
    gpe_entities = [ent.text for ent in doc.ents if ent.label_ == "GPE"]
    for gpe in gpe_entities:
        text = text.replace(gpe, "").strip()
    return text

def extract(text):
    doc = nlp(text)
    company_names = [ent.text for ent in doc.ents if ent.label_ == "ORG"]

    if company_names:
        return company_names[0]  # Return the first extracted company name

    # If no organization entity is found, clean the text
    text = clean_text(text)
    text = remove_geographical_locations(text)

    # Second attempt with manual rule-based approach
    doc = nlp(text)
    company_names = [ent.text for ent in doc.ents if ent.label_ == "ORG"]
    if company_names:
        return company_names[0]  # Return the first extracted company name

    # If still no organization entity is found, assume the cleaned text is the company name
    return text

dfTable['Extracted Companies'] = dfTable['Companies'].apply(extract)

dfTestTable['Extracted Companies M'] = dfTestTable['Companies M'].apply(extract)

def cleanCompanies(series):
  return series.str.lower().str.replace(r"[^a-z\s]","").str.strip()

dfTestTable["coCleanT"] = cleanCompanies(dfTestTable["Extracted Companies M"])

dfTable["coClean"] = cleanCompanies(dfTable["Extracted Companies"])

choices = dfTestTable["coCleanT"].tolist()

def fm(row):
  matches = process.extract(row["coClean"],choices,limit=3)
  exactMatchBool = matches[0][1] == 100
  row["Match"] = matches[0][0]
  row["Match Score"] = matches[0][1]
  return row

dfMatching = dfTable.apply(fm,axis=1)

dfMatching

threshold = 80

error_rates = []
accuracies = []

# Iterate over the DataFrame and calculate accuracy and error rate
for index, row in dfMatching.iterrows():
    match_score = row['Match Score']

    # Calculate accuracy as a percentage based on match score relative to threshold
    if match_score > threshold:
        accuracy = ((match_score - threshold) / (100 - threshold)) * 100
    else:
        # Simplified the conditional to a single else block
        accuracy = ((match_score) / threshold) * 100

    # Calculate error rate as a percentage
    if match_score < 100:
        error_rate = 100.0 - accuracy  # Error rate is the complement of accuracy
    else:
        error_rate = 0.0

    # Assign the values directly to the DataFrame instead of appending to lists
    dfMatching.loc[index, 'Accuracy'] = accuracy
    dfMatching.loc[index, 'Error Rate'] = error_rate

wsMatching = ss.worksheet('Matching')

listScores = [dfMatching.columns.tolist()] + dfMatching.to_numpy().tolist()

wsMatching.update("A1",listScores)